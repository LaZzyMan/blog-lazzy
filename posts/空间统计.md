---
title: '空间统计备忘知识'
date: '2019-09-27 13:19:00'
tags: 
- 论文
---

## 自相关&异质性
空间异质性，一般指的是因为观察位置的不同，而产生的不同观测结果。一般来说，空间异质性，会用来解释，在不同的区域，某些类别数值相互之间的关系产生变化的原因，揭示这个变化的规律或者原因产生积极的作用,这种不同，不仅仅是因为距离的关系，还可能出现其他的条件.

根据地理学第一定律，任何事情呢，都是有关系，只不过靠得越近，关系就越紧密。这种潜在的（因为没有很明显的表现出来，所以肯定是潜在的）的相互依赖性，就是所谓的“空间自相关”。

## 莫兰指数
莫兰指数是一个有理数，经过方差归一化之后，它的值会被归一化到-1.0——1.0之间。$Moran's I >0$表示空间正相关性，其值越大，空间相关性越明显，Moran's I <0表示空间负相关性，其值越小，空间差异越大，否则，$Moran's I = 0$，空间呈随机性。

![](空间统计\01.png)

零假设：指进行统计检验时预先建立的假设。也就是说，你在检验你的结果之前，先对这些结果假设一个数值区间，这个区间一般是符合某种概率分布的情况，如果你的真实结果偏离了你设定的区间，就表示发生了小概率事件。这样你原来的假设就不成立了。

p值（P-Value，Probability，Pr），代表的是概率。它是反映某一事件发生的可能性大小。在空间相关性的分析中，p值表示所观测到的空间模式是由某一随机过程创建而成的概率。比如我说，你计算出来的p值是1，那就表示你用于计算的这份数据，100%是随机生成的了（当然，不可能是1的，0.5以上就也不得了）。如果是0.1，就表示只有10%的可能性是随机生成的结果。

z得分（Zscores）表示标准差的倍数（standarddeviations）。
![](空间统计\02.png)
![](空间统计\03.png)
![](空间统计\04.png)

## 平均最邻近
平均最近邻工具，首先要假设一个在研究区域以内，随机分布的平均距离（记为De）。接下去测量每个 要素的质心，与他最近的那个要素的质心之间的距离；然后把这些测量之后的距离，计算他们的平均值（Do）。最后用Do/De，就得出了平均最近邻指数。

如果De > Do，计算的指数小于1，那么就表示这份数据的模式趋向于聚集。

如果De < Do，计算的指数大于1，那么就表示这份数据的模式趋向于离散。

而这个指数，越接近1，就表示随机的几率越大。
平均最近邻工具最适用于对固定研究区域中不同的要素进行比较。比如在同一城市范围内，不同类型的企业之间的分布情况的研究；或者同一类型的企业，在固定区域以内，随着不同年份的变化情况的研究。
## 中心要素
经典统计学里面，寻找中位数的方法，是对样本数据进行排序，然后按照样本的个数，找到中间的那个数据，在空间统计中，因为无法直接进行排序，所以需要把二维空间点的分布，变成一维的线性排序来寻找。这个变化的方式，就是用点与其他每个点的距离之和，来作为该点的值，如下：
![](空间统计\05.png)

以此类推，把所有点的距离总和都计算出来，然后进行排序，最后距离总和最小的那个点，就是所谓的中心要素。
## 平均值中心
算数平均中心的计算方法也很简单，和所有的空间相关理论都可以直接抛开，直接进行算数计算，这个生成的点的x坐标和y坐标，就是所有点的x坐标和y坐标的平均值
## 中位数中心
中位数中心和中心要素，最大的不同点在于：中心要素计算出来的结果，必须是要素样本的中的一个原始样本；而中位数中心计算出来的，可以不是原始要素中的一个，可以生成一个新的位置。

位数中心，对极值（异常值）的敏感程度要低于算数平均中心。所以：中位数中心是一种对异常值反应较为稳健的中心趋势的量度。
## 标准差椭圆
首先是确定圆心，方向分布工具的圆心，直接利用的是算数平均中心来计算椭圆的圆心。

$SDE_x$和$SDE_y$就是计算出来的椭圆的方差，总所周知，椭圆的大小取决于方差大小，长半轴表示最大方差，短半轴表示最小方差，在空间统计上面，用X、Y的方差进行计算，得到长短半轴。
$$SDE_x=\sqrt{\frac{\Sigma_{i=1}^n(x_i-\bar X)^2}{n}}$$
$$SDE_y=\sqrt{\frac{\Sigma_{i=1}^n(y_i-\bar Y)^2}{n}}$$
$$tan\theta=\frac{A+B}{C}$$
$$A=(\Sigma_{i=1}^n\widetilde x_i^2-\Sigma_{i=1}^n\widetilde y_i^2)$$
$$B=\sqrt{(\Sigma_{i=1}^n\widetilde x_i^2-\Sigma_{i=1}^n\widetilde y_i^2)+4(\Sigma_{i=1}^n\widetilde x_i\widetilde y_i)}$$
$$C=2\Sigma_{i=1}^n\widetilde x_i\widetilde y_i$$
最后确定XY轴的标准差，公式如下：
$$\sigma_x=\sqrt2\sqrt{\frac{\Sigma^n_{i=1}(\widetilde x_icos\theta-\widetilde y_isin\theta)^2}{n}}$$
$$\sigma_y=\sqrt2\sqrt{\frac{\Sigma^n_{i=1}(\widetilde x_isin\theta-\widetilde y_icos\theta)^2}{n}}$$
$$(\frac{x}{\sigma_x})^2+(\frac{y}{\sigma_y})^2=s$$


S是置信度的值，可以根据数据量来查询卡方概率表（Table:Chi-Square Probabilities）

1、椭圆的长半轴表示的是数据分布的方向，短半轴表示的是数据分布的范围，长短半轴的值差距越大（扁率越大），表示数据的方向性越明显。反之，如果长短半轴越接近，表示方向性越不明显。如果长短半轴完全相等，就等于是一个圆了，圆的话就表示没有任何的方向特征。

2、短半轴表示数据分布的范围，短半轴越短，表示数据呈现的向心力越明显；反之，短半轴越长，表示数据的离散程度越大。同样，如果短半轴与长半轴完全相等了，就表示数据没有任何的分布特征。

3、中心点表示了整个数据的中心位置，一般来说，只要数据的变异程度不是很大的话，这个中心点的位置大约与算数平均数的位置基本上是一致的。

## 标准距离
标准距离在空间统计里面也是一个常用的方法，因为它可提供有关中心周围要素分布的单一汇总度量值（此方法类似于通过标准差测量统计平均值周围数据值的分布）。

![](空间统计\06.png)
## 线性方向平均值
![](空间统计\07.png)
圆方差用来表示，你要进行分析的这些数据的方向的变异程度。圆方差范围为 0 至 1。如果所有分析数据具有完全相同（或非常相似）的方向，则圆方差将很小（接近于0）。当输入的数据方向跨越整个罗盘时，圆方差将很大（接近于1）。——圆方差越大，分析的数据之间的方向变化越明显。
## 高低值聚类
Getis-Ord General G分析，公式如下：

![](空间统计\08.png)

Z得分为正——观察General G指数大于期望GeneralG指数——数据在高值区域聚类。

Z得分为负——期望General G指数大于观察GeneralG指数——数据在低值区域聚类。

观察GeneralG指数和期望General G指数相等的情况，那么这种情况用官方的话说，就是高值和低值同时聚类时，它们倾向于彼此相互抵消。

General G一般不能用于对不同区域的数据进行计算比较。因为空间数据对大小和距离都很敏感，同样表现为聚类的，理论上应该观测值等于期望值，但是如果面要素的大小不一样，就会出现，小的面要素会优于大的面要素。

## 增量自相关
以不同的距离作为密度半径来计算莫兰指数，通过p值和z得分来寻找最优的空间自相关密度半径。
![](空间统计\09.png)

## 局部莫兰指数
局莫兰指数是按照所有的数据配合空间权重矩阵计算出来的一个综合的数值，那么局部莫兰指数的计算方法与全局莫兰指数大致是一样，所不同的是没有了权重矩阵和数据值平均数的聚合计算过程。所以在每一个要素上面都会计算出一个属于自己的莫兰指数。局部莫兰指数用于局部的聚类和异常值分析。
![](空间统计\10.png)

X轴反应的是标准化后的局部莫兰指数观测值，正值代表高值聚类而负值代表低值聚类；空间滞后值是由邻居点的标准化莫兰指数观测值加权平均得到的。
## 热点分析（Getis-OrdGi* 统计）
![](空间统计\11.png)

热点区域表示他不但本身的数值很高，而且他周边的数值也很高，是高值和高值的聚集区。同样的，冷点表示的是不但本身的值很低，旁边的值也很低，就是所谓的低值和低值的聚集区。
## 回归分析
回归的观点：
- 因果：这种观点的把结构部分称之为“机制项”，即研究者想通过一个确定一个模型来发现这些数据事件产生的机制——找到因果关系。而随机部分，认为是对这种因果关系的一种干扰。
- 预测：通常是通过已知的一组自变量和因变量之间的关系后，用新的自变量来预测对应的因变量。
- 描述数据：数据体现的是客观情况，和因果以及未来没有关系（无因有果和黑天鹅）。统计模型的主要目标在于用最简单的结构和尽可能少的参数来概括大量数据所包含的主要信息。
![](空间统计\12.png)

使用残差平方和最小作为条件利用拉格朗日乘数法得到回归直线的斜率和截距。

结果数据：
- Coefficient系数
- Stderr
- t统计量：T-Statistic=平均值 / 标准误
- p值
- Robust_SE Robust_t Robust_Pr：在统计学里面，Robust Test通常被翻译稳健性检验，一般来说，就是通过修改（增添或者删除）变量值，看所关注解释变量的回归系数和结果是否稳健。
- VIF （方差膨胀因子（Variance Inflation Factor，VIF）），这个值主要验证解释变量里面是否有冗余变量（即是否存在多重共线性）。一般来说，只要VIF超过7.5，就表示该变量有可能是冗余变量。
- Multiple R-Squared：多重R平方系数，常指的是自变量方程对因变量的解释能力。比如等于0.8的时候，表示回归方程能够解释80%的因变量的变化。
- Adjusted R-Squared：校正R平方系数，通常要比多重R平方系数要稍微低一些，因为这个系数的技术与数据的情况关系更强，所以对模型的性能评估也更加准确一些。
- Joint F-Statistic 联合F统计量
- Prob(>F) degrees of freedom F统计量的可信概率的自由度
- Joint Wald Statistic 联合卡方统计量
- Prob(>chi-squared) degrees of freedom 卡方统计量的可信概率的自由度

## 地理加权回归
当一个数据，在A区域内有很强的解释能力，比如在威海市，人口数量对财政收入的变化，可解释性超过了96%，但是同样居于鲁东的青岛，只有1%，简直就不能用不显著来形容。这种在不同区域具有不同性质的情况，就是在空间分析里面无所不在的空间异质性了。

这种因为地理位置的变化，而引起的变量间关系或结构的变化称之为空间非平稳性（spatial nonstationarity)），注意，这个图词语空间异质性，之间是不能画等号的。初略说起来，可以认为空间非平稳性是空间异质性的一种表现形式。
在空间上出现的非平稳性，通常被认为由以下三个方面的原因引起的：

- 随机抽样的误差引起的。抽样误差是无法避免的，也是无法观察的，所以统计学上一般只假定它服从某一分布，没必要去死纠这种变化，因为对分析本身的关系作用不大。
- 是由于各地区不同的自然环境、人文环境等差异所引起的变量间的关系随着地理位置的变化而变化。这种变化反应是数据本身的空间特性，所以在空间分析中是需要着重注意的地方。
- 用于分析的模型与实际不符，或者忽略了模型中应有的一些回归变量而导致的空间非平稳性。

![](空间统计\13.png)
地理加权和其他回归分析一样，首先要划定一个研究区域，当然，通常这个区域也可以包含整个研究数据的全体区域（以此扩展，你可以利用空间关系（比如k-临近），进行局部地理加权计算）……接下去最重要的就是利用每个要素的不同空间位置，去计算衰减函数，这个是一个连续的函数，有了这个衰减函数，当你把每个要素的空间位置（一般是坐标信息（x,y))和要素的值带入到这个函数里面之后，就可以得到一个权重值，这个值就可以带入到回归方程里面去。

在实际应用中，使用交叉验证的方式通过模型拟合值或计算AIC（最小信息准则）来选择最佳带宽b。最常用的空间权重函数是高斯函数，但是如果数据非常离散，带来的结果就是有大量的数据躲得远远的，这种所谓的“长尾效应”会带来大量的计算开销，所以在实际运算中，应用的是近高斯函数来替代高斯计算，把那些没有影响（或者影响很少）的点给截掉，以提高效率，在fotheringham教授1998年的论文里面，也提出，采用bi-square函数来进行计算。

$$AIC = （2(模型的独立参数个数)-2ln(模型的极大似然函数))/观测值个数$$
