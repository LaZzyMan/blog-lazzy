---
title: 'Visualizing the Impact of Feature Attribution Baselines'
date: '2021-01-11 11:42:00'
tags: 
- 论文

category: Research
image: \阅读笔记15\16.jpg
---

[原论文网页](https://distill.pub/2020/attribution-baselines/)

## Introduction

积分梯度用于计算神经网络中，对于每一个点的预测结果特征的重要性，从而帮助人们更好地理解和解释预测模型。积分梯度方法中存在唯一的超参数——基准值（baseline）的选择是一个很少被讨论的问题，本文讨论了基准值选择的起源和重要性，以图像分类作为例，对比不同的基准值选择对影响力可视化的作用，并给出多种缺失值（包括恒定基准和基于分布的基准），最后对比这些基准值选择方法并讨论为何量化评估仍十分困难。

## Image Classification

使用Inception V4模型（在ImageNet数据集上训练的CNN），从Tensorflow-Slim下载模型权重作为测试对象。

文章将机器学习的模型解释方法分为三类：
-  methods to visualize and understand how the network represents inputs internally
- feature attribution methods that assign an importance score to each feature for a specific input
- saliency methods that aim to highlight which regions of an image the model was looking at when making a decision

这三种方法并不互斥，归因方法可以可视化为显著性方法，显著性方法也可以为每个特征单独计算重要性分数，而文章中主要针对集成梯度的特征归因方法进行研究。通过集成梯度计算特征归因，得到如下结果：

![](../public\阅读笔记15\01.jpg)

## A Better Understanding of Integrated Gradients

积分梯度方法对于第$i$个特征的重要性定义：

$$\phi_i^{IG}(f,x,x')=(x_i-x_i')\times\int^1_{\alpha=0}\frac{\partial f(x'+\alpha(x-x'))}{\partial x_i }d\alpha$$

其中$x$表示当前输入，$f$表示模型函数，$x'$代表表示缺失的基准值，下标$i$表示索引到第$i$个特征。积分梯度通过对基准值到当前输入值之间插值的梯度进行累计计算重要性得分。使用这种计算方式的原因在于：虽然梯度作为最初的显著性归因方法可以表示像素相对于最终输出的局部斜率，但是存在梯度饱和现象，即使网络严重依赖于某一特征，该特征在输入样本周围的梯度可能会很小。绘制从基准值到当前输入值插值之间图像的模型最终输出可以得到如下的结果：

![](../public\阅读笔记15\05.jpg)

通过在路径上积分，积分梯度避免了局部梯度饱和的问题。因此可以将积分梯度分解为三个部分：
- 基准值和输入值之间的插值图像
- 插值图像的梯度
- $\alpha$上的累积梯度

将这三个部分分别可视化有助于更好地理解积分梯度的原理：
  
![](../public\阅读笔记15\06.jpg)

积分梯度可以满足一些理想特性，包括完整性公理（Axiom 1: Completeness）：

$$\Sigma_i\phi_i^{IG}(f,x,x')=f(x)-f(x')$$

每个特征的重要性分数代表其对于网络输出的独立贡献，并且累加在一起就可以恢复出原本的输出值。这一性质可以帮助度量积分梯度的收敛：在实际中使用离散的黎曼定积分近似计算，通过计算$|\Sigma_i\phi_i^{IG}(f,x,x')-(f(x)-f(x'))|$来判断当前选择的k值是否使得近似收敛。

## Game Theory and Missingness

积分梯度的灵感来源于基于合作博弈论的Shapley值。在合作博弈论中，非原子博弈是一种用于对大型经济系统进行建模的结构，在这种系统中，有足够多的参与者希望对其进行连续贡献，Shapley值提供了一种基于理论的方法来确定参与者对系统的贡献。在博弈论中，缺失的概念是明确定义的，博弈是在联盟（参与者的集合）上定义的，对于任何特定联盟，系统的参与者可以在该联盟内外。通过计算如果将更多的参与者组添加到任何给定的联盟中，则博弈的价值将增加多少，从而计算出一组参与者为博弈增加的价值。

为了将这一理论迁移到神经网络模型中，需要对于缺失值的定义和计算从缺失值到当前已知值之间插值的方法，这正是积分梯度所进行的工作。但是对于缺失值的定义却并不容易，通常的零值可能会导致错误的特征解释。以图像分类为例，如果使用恒定的黑色图像作为基准，即使黑色像素构成了感兴趣的对象，积分梯度也不会突出显示黑色像素。因此缺失值的选择十分重要：我们不希望积分梯度给予缺失值重要的贡献值，但如何避免其给予缺失值零贡献。

![](../public\阅读笔记15\07.jpg)

## Alternative Baseline Choices

很明显，任何恒定的颜色基线都会出现此问题。因此文章中提出并比较了对于图像域中，基线的四个替代选择方法。

### The Maximum Distance Baseline

从当前图像获取有效像素范围内曼哈顿距离最远的图像作为基准值，将其称为最大距离基准，可以直接避免与基准之间差异的问题。

![](../public\阅读笔记15\08.jpg)

### The Blurred Baseline

最大距离基准的问题在于其实际上并不是缺失值，而是包含了关于原始图像的大量信息，从而使预测值并非从缺失值出发。为了解决这一问题可以使用图像的模糊版本作为图像的基准值，并通过平滑系数对基准值进行调节。

![](../public\阅读笔记15\09.jpg)

### The Uniform Baseline

模糊基准的潜在问题在于其倾向于突出高频信息，由于基准被定义为像素与邻近像素的加权平均值，与邻近像素值相近的像素的归因值会低于与邻近像素差异较大的像素。定义缺失值的另一种方法是在有效像素范围内，进行随机的均匀采样来作为基准值。

![](../public\阅读笔记15\10.jpg)

### The Gaussian Baseline

区别与均匀随机基准，可以通过以当前图像为中心的标准差为$\sigma$的高斯分布图像来作为基准图像，由于在有效像素范围内将高斯分布截断，当标准差趋近于无穷时，高斯基准会退化为均匀采样基准。

![](../public\阅读笔记15\11.jpg)

## Averaging Over Multiple Baselines

通过随机采样得到而基于分布的基准值同样存在问题，因为像素存在着一定的概率与基准值相近，从而不会被认为是重要的特征。最简单的方法是对多个基准值进行平均。虽然这种方式对于恒定基准值并不合适，但对于从分布中得到的基准值非常自然，只需从相同的分布中抽取更多样本，然后平均每个样本的重要性得分即可。

### Assuming a Distribution

解释这一想法需要回到积分梯度的原始定义中，积分梯度定义中假设基准值$x'$为一个常数值，而通过平均从统一分布$D$中得到的基准值相当于假设基准值服从于这一分布，从而有：

$$\phi_i(f,x)=\int_{x'}\phi_i^{IG}(f, x, x')\times p_D(x')dx'$$

从直觉上来讲，这一假设可能比恒定值假设更为合理，但也带来了新的问题，只是从选择恒定值$x'$变为了选择分布$D$。

### Expectations, and Connections to SmoothGrad

将二重积分分别视为分布$D$和路径$x$到$x'$上的期望，将其定义为期望梯度（Expected Gradients)：

$$\phi_i^{EG}(f,x;D)=\mathbb{E}_{x'\sim D,\alpha \sim U(0,1)}[(x_i-x_i')\times \frac{\partial f(x'+\alpha(x-x'))}{\partial x_i}]$$

由于期望梯度和积分梯度都是基于路径的归因方法，在实际计算中期望梯度的似然值表示为：

ps：此处存在问题，期望梯度并不能算作积分梯度原文中指出的多路径归因方法，因为积分变量$x'$作为路径的起点对于每一条路径是不同的，因此也不能利用原文中提出的聚合方法得到下式中的路径积分结果。

$$\hat{\phi_i}^{EG}(f,x;D)=\frac{1}{k}\Sigma^k_{j=1}(x_i-x_i'^j)\times \frac{\partial f(x'^j+\alpha^j(x-x'^j))}{\partial x_i}$$

其中$x'^j,\alpha^j$分别表示分布D和[0,1]均匀分布上的第j个采样点，如果假设基准值服从高斯分布，则有：

$$\hat{\phi_i}^{EG}(f,x;N(x,\sigma^2I))=\frac{1}{k}\Sigma^k_{j=1}\epsilon^j_{\sigma}\times \frac{\partial f(x+(1-\alpha^j)\epsilon^j_{\sigma})}{\partial x_i}$$

其中$\epsilon_{\sigma}\sim N(0, \sigma^2I)$，这一形式与SmoothGrad十分相似。使用高斯分布的期望梯度假设了像素之间分布的独立性，这可能会更好地突出显著像素并减少噪声，因此解释了SmoothGrad方法得到的显著图较为光滑的原因——隐含了像素的独立性。使用$gradients\times input$形式的SmoothGrad表示为：

$$\phi_i^{SG}(f,x;N(0,\sigma^2I))=\frac{1}{k}\Sigma^k_{j=1}(x+\epsilon^j_{\sigma})\times \frac{\partial f(x+\epsilon^j_{\sigma})}{\partial x_i}$$

### Using the Training Distribution

至此，需要思考的问题在于，假设像素之间的独立性是否合理。在监督学习中，我们假设数据来自于某一分布$D_{data}$，训练和测试数据共享一个共同的基础分布的假设是使我们能够进行监督学习并声称可推广性的原因。通过这一假设，就可以不再使用高斯分布或均匀分布来建模缺失值，而是直接使用$D_{data}$。虽然不能得到$D_{data}$的真是分布，但是我们可以将训练数据集作为数据分布的独立采样，从而将期望梯度分为三个部分（插值图像、插值图像梯度和累积插值梯度）并进行可视化：

$$\frac{1}{k}\Sigma^k_{j=1}(x_i-x_i'^j)\times \frac{\partial f(x'^j+\alpha^j(x-x'^j))}{\partial x_i}=\hat{\phi_i}^{EG}(f,x,k;D_{data})$$

![](../public\阅读笔记15\12.jpg)

可以肯定的是，当在路径和分布上进行积分时，更难以满足完整性要求：也就是说，在样本数量相同的情况下，期望的梯度收敛速度不会像积分梯度那样快，而为了避免盲目解释，这种代价是否可以接受是一个主观问题。

ps：这里存在更为严重的逻辑问题，即图4中的蓝色直线值代表的意义不明，根据这一错误推导得到的公式在不确定的基准值上计算积分，$|f(x)-f(x')|$的值理应不是一个确定值，而这里直接使用了上文使用的全零值图片计算得到的$f(x')$来作为基准值输出，不可能得到收敛结果。

## Comparing Saliency Methods

对于基准选择的多种方法，如何评估显著图的效果依旧是一个难题，本节介绍了当前的一些评价指标和方法。

### The Dangers of Qualitative Assessment

当依赖视觉进行定性评估时，我们假设人类知道准确的显著图，例如在图像分类任务中，通常检查显著图是否突出了图中的真实类的对象，我们首先在数据和标签之间建立假设，之后假设良好的显著图可以反映出这一假设，但这种做法其实没有任何正当的理由。举例来说，对于一个MNIST数据集变体（左上角区域编码了类别），边缘检测的结果更符合人类视觉的定性认知标准，而归因方法会将左上编码区域赋予更高的重要性（网络分类的实际依赖特征）。

![](../public\阅读笔记15\13.jpg)

### Top K Ablation Tests

Top K 消融方法将归因方法得到的最显著的k个特征进行消融，计算预测输出的对数损失值来衡量归因方法的效果。分别通过均值输入和高斯模糊（Mean top K & Blur Top K）来对前k个特征进行消融，对比对于1000个样本图像进行归因的结果，作为对比，加入了随机噪声（对特征进行随机排名）。使得网络原有输出对数幅度下降最快的基准选择是表示其突出显示了最能增加网络置信度的像素，因此曲线越低对应的极限选择效果越好。

![](../public\阅读笔记15\15.jpg)
![](../public\阅读笔记15\14.jpg)

### Mass Center Ablation Tests

Top k消融方法存在的问题在于没能考虑图像像素的相关性，即无论如何消融一个像素，该像素周围的像素还会提供关于像素原始值的大量信息。解决这一问题的方法是质心消融测试，计算显著图的质心，并消融以质心为中心的一定区域，从而测试显著图是否突出显示了图像的重要区域。同样分别使用均值输入和高斯模糊输入进行对比，并加入随机噪声（从高斯随机噪声中生成的显著图）。所有基准选择方法得到的结果相似，稍微高于对照组，原因可能是一般图像的重要区域都位于图像的中心区域。

![](../public\阅读笔记15\16.jpg)
![](../public\阅读笔记15\17.jpg)

### The Pitfalls of Ablation Tests

有学者指出，对特征进行消融会得到与训练集数据不同分布的数据，而对于通过训练集训练得到的模型，我们的模型从未见过这些不同分布的数据，我们为什么期望从评估模型中提取任何合理的信息？但另一方面来讲，积分梯度所使用的插值图像输入同样不属于原数据分布。是否应该向模型提供不属于训练数据分布的数据这一问题一直饱受争议，因为这涉及到模型性能的下降是源于数据分布变化还是消融的功能确实具有实际价值。

一种提出的解决方法是，首先对训练集和测试集上的特征更加显著图进行消融，之后以此训练新的模型，比较新模型与原模型的效果作为归因效果的评价指标。但这种方式同样会受到特征相关性的影响，假设高度相关的特征1和2对预测任务效果显著，模型十分依赖特征1而完全忽略特征2，得到的归因结果赋予特征1高重要性和特征2低重要性，消融特征1后重新训练模型依赖特征2得到了与原模型近乎相同的效果，这是否说明归因方法效果极差？因此，这其中也涉及到归因方法是对模型正确还是对数据正确的讨论。（上述例子中归因方法对模型正确，但是对数据不正确）

综上所述，评估一个监督模型十分简单，因为我们有测试集来计算评价指标，而评估一个解释模型十分困难，因为我们不知道模型做了什么，也没有真实的显著图来作为比较。