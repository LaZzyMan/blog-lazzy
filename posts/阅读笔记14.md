---
title: 'AM-GCN: Adaptive Multi-channel Graph Convolutional Networks'
date: '2020-12-11 11:42:00'
tags: 
- 论文

category: Research
---

## INTRODUCTION

Problems：
- What information do GCNs really learn and fuse from topological structures and node features?
- Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially?

Contributions:
- We present experiments assessing the capability of GCNs in fusing topological structures and node features and identify the weakness of GCN. We further study the important prob￾lem, i.e., how to substantially enhance the fusion capability of GCN for classification.
- We propose a novel adaptive multi-channel GCN framework, AM-GCN, which performs graph convolution operation over both topology and feature spaces. Combined with attention mechanism, different information can be adequately fused.
- Our extensive experiments on a series of benchmark data sets clearly show that AM-GCN outperforms the state-of￾the-art GCNs and extracts the most correlation information from both node features and topological structures nicely for challenging classifcation tasks.

## FUSION CAPABILITY OF GCNS: AN EXPERIMENTAL INVESTIGATION

为了检测GCN对于网络中节点特征和网络拓扑结构特征的融合作用，文中设计了两组实验：

**Case 1: Random Topology and Correlated Node Features**：创建900个节点的随机网络，以0.03的概率连接节点；为每个节点生成50个特征和标签，所有节点的特征通过高斯正态分布生成，具有相同的协方差矩阵；不同标签节点特征正态分布中心不同，该网络中节点标签与节点特征高度相关，与网络拓扑结构无关。

对于每一类别，选择20个节点作为训练集，200个节点作为测试集，分别使用GCN和MLP（只通过节点特征分类）进行分类，分类精度分别为75.2%和100%。GCN可以融合节点特征与网络拓扑结构特征，但它无法自适应的调整融合方式来规避结构特征带来的干扰。

**Case 2: Correlated Topology and Random Node Features**：创建900个节点构成的网络，节点同样赋予50个特征，但特征值随机生成；使用随机块模型(SBM)将网络划分为三个社区，在每个社区中以0.03的概率连接节点，而在不同社区的节点间以0.0015的概率生成连接。该网络中节点标签与网络拓扑结构（社区）相关而与节点特征无关。

同样的，对于这一网络分别使用GCN和DeepWalk进行节点分类，分类精度分别为87%和100%。因此，总的来说，即使在存在非常显著的相关性的情况下，GCN仍然无法自适应的优化节点特征与网络结构特征的融合机制。

## AM-GCN: THE PROPOSED MODEL

问题描述：在半监督分类问题中，对于带属性图$G=(A,X)$，其中$A\in R^{n\times n}$表示图的对称邻接矩阵，$X\in R^{n\times d}$表示节点特征矩阵，每个节点都属于类别$C$中的一类。AM-GCN的网络结构如图：

![](../public\阅读笔记14\01.jpg)

首先，通过节点特征相似性构建特征网络，使节点特征分别在拓扑网络和特征网络汇总传播得到节点表示$Z_T, Z_F$。考虑到两类特征中存在协同作用部分，构建共享参数的协同卷积模块得到节点的协同表示$Z_{CT}, Z_{CF}$，同时通过一致性约束$L_C$来增强$Z_{CT}$和$Z_{CF}之间的协同性，并通过独立性约束$L_C$约束保证协同特征与单个特征之间的独立性。最后，通过注意力机制来根据分类任务完成特征的自适应融合。

### Specific Convolution Module
首先基于节点特征创建kNN网络$G_f=(A_f,X)$来捕捉节点特征空间的潜在结构，其中节点特征邻接矩阵$A_f$通过相似度矩阵构建，文中通过余弦相似度度量节点特征$x_i,x_j$的相似性。通过$G_f$可以得到基于节点特征的节点表示：
$$Z_f^{(l)}=ReLU(\tilde{D}_f^{-\frac{1}{2}}\tilde{A}_f\tilde{D}_f^{-\frac{1}{2}}Z_f^{(l-1)}W^{(l)}_f)$$

网络最后一层的输出表示为$Z_F$代表特征空间中的具体信息（specific information）。而对于拓扑空间，$G_t=(A, X)$通过传统的GCN网络得到拓扑空间的具体信息表示$Z_T$。

### Common Convolution Module
由于特征空间域拓扑空间并非完全独立的，因此不仅需要单独提取两个空间中的节点表示，还需要提取两个空间共享的节点表示特征，本文通过共享参数的策略提取两个空间共享的嵌入表示：

$$Z_{ct}^{(l)}=ReLU(\tilde{D}_t^{-\frac{1}{2}}\tilde{A}_t\tilde{D}_t^{-\frac{1}{2}}Z_{ct}^{(l-1)}W^{(l)}_c)$$

$$Z_{cf}^{(l)}=ReLU(\tilde{D}_f^{-\frac{1}{2}}\tilde{A}_f\tilde{D}_f^{-\frac{1}{2}}Z_{cf}^{(l-1)}W^{(l)}_c)$$

通过共享GCN模块，提取共享特征$Z_{CF},Z_{CT}$，将共享特征表示为$(Z_C=Z_{CF}+Z_{CT})/2$。

### Attention Mechanism

对于两个空间的单独特征$Z_F,Z_T$和共享特征$Z_C，通过注意力机制来学习其重要性：

$$(\alpha_t,\alpha_c,\alpha_f)=attr(Z_T,Z_C,Z_F)$$

其中$\alpha_t,\alpha_c,\alpha_f\in R^{n\times 1}$表示对于每个节点，各个表示特征的重要性。对于某一个节点的拓扑特征表示向量$z_T^i\in R^{h\times 1}$，首先通过非线性变换和一个共享吸引力向量$q\in R^{h'\times 1}$来计算注意力值：

$$\omega_T^i=q^T\cdot tanh(W\cdot (z_T^i)^T+b)$$

其中$W\in R^{h'\times h},b\in R^{h'\times 1}$分别是权重矩阵和偏置矩阵。同样的方法计算得到特征空间表示和共享表示的注意力值，通过softmax计算注意力权重：

$$\alpha_T^i=softmax(\omega_T^i)=\frac{exp(\omega_T^i)}{exp(\omega_T^i)+exp(\omega_C^i)+exp(\omega_F^i)}$$

通过计算得到的注意力权重得到最终的节点嵌入表示：

$$Z=\alpha_T\cdot Z_T+\alpha_C\cdot Z_C+\alpha_F\cdot Z_F$$

### Objective Function

**Consistency Constraint**通过$L_2$正则化对$Z_{CT},Z_{CF}$进行正则化，进而计算n个节点的相似性：

$$S_T=Z_{CTnor}\cdot Z_{CTnor}^T$$

$$S_F=Z_{CFnor}\cdot Z_{CFnor}^T$$

一致性要求两个相似矩阵是相似的，因此可以得到一致性约束：

$$L_C=\rVert S_T-S_F\rVert^2_F$$

**Disparity Constraint**

由于$Z_T,Z_{CT}$学习自相同的网络$G_t$，因此为了保证特征的独立性，使用HISC（Hilbert-Schmidt Independence Criterion）来度量二者的独立性：
$$HISC(Z_T,Z_{CT})=(n-1)^{-2}tr(RK_TRK_{CT})$$

$$L_d=HISC(Z_T,Z_{CT})+HISC(Z_F,Z_{CF})$$

**Optimization Objective**

网络输出：

$$\hat{Y}=softmax(W\cdot Z+b)$$

交叉熵计算多分类损失函数：

$$L_t=-\sum_{l\in L}\sum^C_{i=1}Y_{l_i}ln\hat{Y}_{l_i}$$

优化目标：

$$L=L_t+\gamma L_c+\beta L_d$$

## EXPERIMENTS
优化策略带来的提升：
![](../public\阅读笔记14\02.jpg)

通过注意力机制，还可以衡量节点特征空间和拓扑空间与分类任务的相关性以及训练过程中的变化趋势：
![](../public\阅读笔记14\03.jpg)

## Summary

- 使用特征向量+特征图提取节点特征信息
- 通过注意力机制聚合特征信息、拓扑结构信息和共享信息
- 引入一致性和独立性限制
